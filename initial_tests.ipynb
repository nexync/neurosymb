{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lnn import Model, Predicates, Variable, And, Or, Proposition, Implies, World\n",
    "import torch.nn as nn\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m      5\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     next_state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(\u001b[39m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m      8\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "maxvel = 0\n",
    "maxangvel = 0\n",
    "for i in range(100):\n",
    "    env.reset()\n",
    "    while True:\n",
    "        next_state, reward, done, _ = env.step(0)\n",
    "        if done:\n",
    "            break\n",
    "        if abs(next_state[1]) > maxvel:\n",
    "            maxvel = abs(next_state[1])\n",
    "        if abs(next_state[3]) > maxangvel:\n",
    "            maxangvel = abs(next_state[3])\n",
    "print(maxvel, maxangvel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocities = np.linspace(-2, 2, 41)\n",
    "angvelocities = np.linspace(-3, 3, 61)\n",
    "pos = np.linspace(-1.2, 1.2, 25)\n",
    "ang = np.linspace(-0.2094395, 0.2094395, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNNModel():\n",
    "\tdef __init__(self, n_velocity_inputs, n_ang_velocity_inputs, n_pos_inputs, n_ang_inputs, n_outputs):\n",
    "\t\tself.model = Model()\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNNCartpoleAgent:\n",
    "\tdef __init__(self):\n",
    "\t\tself.left_lnn = LNNModel()\n",
    "\t\tself.right_lnn = LNNModel()\n",
    "\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lnn import Propositions, Fact, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "a,b,c = Propositions(\"a\", \"b\", \"c\")\n",
    "a1 = And(a,b)\n",
    "i1 = Implies(a1, c)\n",
    "model.add_knowledge(a1)\n",
    "model.add_knowledge(i1, world=World.AXIOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_data({\n",
    "\ta: (0.9, 1.0),\n",
    "\tb: (0.9, 1.0)\n",
    "})\n",
    "\n",
    "model.add_labels({\n",
    "\tc: Fact.FALSE\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************************************************************\n",
      "                                LNN Model\n",
      "\n",
      "AXIOM Implies: ((a ∧ b) → c)                                TRUE (1.0, 1.0)\n",
      "\n",
      "OPEN Proposition: c                                      UNKNOWN (0.0, 1.0)\n",
      "\n",
      "OPEN And: (a ∧ b)                                        UNKNOWN (0.0, 1.0)\n",
      "\n",
      "OPEN Proposition: b                                  APPROX_TRUE (0.9, 1.0)\n",
      "\n",
      "OPEN Proposition: a                                  APPROX_TRUE (0.9, 1.0)\n",
      "\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not Loss",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mtrain(losses\u001b[39m=\u001b[39;49mLoss\u001b[39m.\u001b[39;49mSUPERVISED)\n\u001b[0;32m      2\u001b[0m model\u001b[39m.\u001b[39mprint(params\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Jeffrey\\anaconda3\\envs\\neurosymb\\lib\\site-packages\\lnn\\model.py:667\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, losses, **kwds)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincrement_param_history(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mparameter_history\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    666\u001b[0m _, facts_inferred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m--> 667\u001b[0m loss_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_fn(losses)\n\u001b[0;32m    668\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(loss_fn)\n\u001b[0;32m    669\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loss\u001b[39m.\u001b[39mgrad_fn:\n",
      "File \u001b[1;32mc:\\Users\\Jeffrey\\anaconda3\\envs\\neurosymb\\lib\\site-packages\\lnn\\model.py:741\u001b[0m, in \u001b[0;36mModel.loss_fn\u001b[1;34m(self, losses)\u001b[0m\n\u001b[0;32m    737\u001b[0m         result\u001b[39m.\u001b[39mappend(coalesce)\n\u001b[0;32m    738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    739\u001b[0m     kwds \u001b[39m=\u001b[39m (\n\u001b[0;32m    740\u001b[0m         losses[loss]\n\u001b[1;32m--> 741\u001b[0m         \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(losses[loss], \u001b[39mdict\u001b[39m))\n\u001b[0;32m    742\u001b[0m         \u001b[39melse\u001b[39;00m ({\u001b[39m\"\u001b[39m\u001b[39mcoeff\u001b[39m\u001b[39m\"\u001b[39m: losses[loss]})\n\u001b[0;32m    743\u001b[0m     )\n\u001b[0;32m    744\u001b[0m     result\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    745\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traverse_execute(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mlower()\u001b[39m}\u001b[39;00m\u001b[39m_loss\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    746\u001b[0m     )\n\u001b[0;32m    747\u001b[0m \u001b[39mif\u001b[39;00m result[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not Loss"
     ]
    }
   ],
   "source": [
    "model.train(losses=Loss.SUPERVISED)\n",
    "model.print(params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not Loss",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [77], line 35\u001b[0m\n\u001b[0;32m     25\u001b[0m model\u001b[39m.\u001b[39madd_labels({\n\u001b[0;32m     26\u001b[0m     AB: {\n\u001b[0;32m     27\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m: Fact\u001b[39m.\u001b[39mTRUE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     }\n\u001b[0;32m     32\u001b[0m })\n\u001b[0;32m     34\u001b[0m \u001b[39m# train the model and output results\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m model\u001b[39m.\u001b[39;49mtrain(losses\u001b[39m=\u001b[39;49mLoss\u001b[39m.\u001b[39;49mSUPERVISED)\n\u001b[0;32m     36\u001b[0m model\u001b[39m.\u001b[39mprint(params\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Jeffrey\\anaconda3\\envs\\neurosymb\\lib\\site-packages\\lnn\\model.py:667\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, losses, **kwds)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincrement_param_history(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mparameter_history\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    666\u001b[0m _, facts_inferred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m--> 667\u001b[0m loss_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_fn(losses)\n\u001b[0;32m    668\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(loss_fn)\n\u001b[0;32m    669\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loss\u001b[39m.\u001b[39mgrad_fn:\n",
      "File \u001b[1;32mc:\\Users\\Jeffrey\\anaconda3\\envs\\neurosymb\\lib\\site-packages\\lnn\\model.py:741\u001b[0m, in \u001b[0;36mModel.loss_fn\u001b[1;34m(self, losses)\u001b[0m\n\u001b[0;32m    737\u001b[0m         result\u001b[39m.\u001b[39mappend(coalesce)\n\u001b[0;32m    738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    739\u001b[0m     kwds \u001b[39m=\u001b[39m (\n\u001b[0;32m    740\u001b[0m         losses[loss]\n\u001b[1;32m--> 741\u001b[0m         \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(losses[loss], \u001b[39mdict\u001b[39m))\n\u001b[0;32m    742\u001b[0m         \u001b[39melse\u001b[39;00m ({\u001b[39m\"\u001b[39m\u001b[39mcoeff\u001b[39m\u001b[39m\"\u001b[39m: losses[loss]})\n\u001b[0;32m    743\u001b[0m     )\n\u001b[0;32m    744\u001b[0m     result\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    745\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traverse_execute(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mlower()\u001b[39m}\u001b[39;00m\u001b[39m_loss\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    746\u001b[0m     )\n\u001b[0;32m    747\u001b[0m \u001b[39mif\u001b[39;00m result[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not Loss"
     ]
    }
   ],
   "source": [
    "# construct the model from formulae\n",
    "model = Model()\n",
    "p1, p2 = Predicates(\"P1\", \"P2\")\n",
    "x = Variable(\"x\")\n",
    "AB = And(p1(x), p2(x))\n",
    "model.add_knowledge(AB)\n",
    "\n",
    "# add data to the model\n",
    "model.add_data({\n",
    "    p1: {\n",
    "        \"0\": Fact.TRUE,\n",
    "        \"1\": Fact.TRUE,\n",
    "        '2': Fact.FALSE,\n",
    "        '3': Fact.FALSE\n",
    "    },\n",
    "    p2: {\n",
    "        '0': Fact.TRUE,\n",
    "        '1': Fact.FALSE,\n",
    "        '2': Fact.TRUE,\n",
    "        '3': Fact.FALSE,\n",
    "    }\n",
    "})\n",
    "\n",
    "# add supervisory targets\n",
    "model.add_labels({\n",
    "    AB: {\n",
    "        '0': Fact.TRUE,\n",
    "        '1': Fact.FALSE,\n",
    "        '2': Fact.TRUE,\n",
    "        '3': Fact.FALSE,\n",
    "    }\n",
    "})\n",
    "\n",
    "# train the model and output results\n",
    "model.train(losses=Loss.SUPERVISED)\n",
    "model.print(params=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "485ac74c0b2c0c29bdc4a85350329fba24a8b626c130ffae8fdc15f65cd2a06c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
